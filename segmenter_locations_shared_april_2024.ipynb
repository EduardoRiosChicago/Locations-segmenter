{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc04d1de-c28f-4604-af73-af321f2044ee",
   "metadata": {},
   "source": [
    "# Segmenter_Locations_shared. April, 2024.\n",
    "Cell definitions are dictated by convenience in execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9517d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 17:59:51) [MSC v.1935 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from test_utils import summary   #print(tf.__version__)\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import statistics\n",
    "print(sys.version)  #Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a8e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "image_path = os.path.join(path, 'C:/Users/erios/EM_Images/split_Penn_train/')\n",
    "mask_path = os.path.join(path, 'C:/Users/erios/EM_Images/split_Penn_train_locations_labels/')  \n",
    "image_list_orig = os.listdir(image_path)                  # list within the folder\n",
    "mask_list_orig = os.listdir(mask_path)                    # list within the folder\n",
    "image_list = [image_path+i for i in image_list_orig]      # full path and filename\n",
    "mask_list = [mask_path+i for i in mask_list_orig]         # image_list and mask_list are class lists and have no dtype\n",
    "image_filenames = tf.constant(image_list)                 # tensor, dtype = string\n",
    "mask_filenames = tf.constant(mask_list)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_filenames, mask_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedfe902-778a-4d7f-a8fd-1419aca21a67",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea57014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess, Data Augmentation\n",
    "seed = (1, 2)\n",
    "ran = tf.keras.layers.RandomContrast(0.4)       # RandomContrast of 0.4. Less than for granules.  Must check.\n",
    "def process_path(image_path, mask_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=0, dtype=tf.dtypes.uint16)\n",
    "    return img, mask\n",
    "\n",
    "def preprocess(image, mask):\n",
    "    global seed\n",
    "    seed = (seed[0] + random.randint(0, 10000), seed[1] + random.randint(0, 10000))\n",
    "    #changes the seed randomly\n",
    "    \n",
    "    input_image = tf.image.resize(image, (1024,1024), method='nearest')\n",
    "    input_mask = tf.image.resize(mask, (1024,1024), method='nearest')\n",
    "    input_image = tf.image.stateless_random_flip_left_right(input_image, seed)\n",
    "    input_mask = tf.image.stateless_random_flip_left_right(input_mask, seed)\n",
    "    input_image = tf.image.stateless_random_flip_up_down(input_image, seed)\n",
    "    input_mask = tf.image.stateless_random_flip_up_down(input_mask, seed)\n",
    "    input_image = ran(input_image)\n",
    "    input_image = tf.image.random_brightness(input_image, 0.25)  # RandomBrightness 0.25.  Same as granules. Must check.\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "# prediction from model outputs\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "    \n",
    "def show_predictions(dataset=None, num=2):\n",
    "    \"\"\"\n",
    "    Displays the first image of each of the num batches\n",
    "    \"\"\"\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = unet_loc.predict(image)                           # model name changed to unet_loc\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "            create_mask(unet_loc.predict(sample_image[tf.newaxis, ...]))])\n",
    "\n",
    "# utility for display. image tensors must be rank 3\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05099291-6462-43b6-953e-24990ca96dcb",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d16039-1d29-455b-b922-934fd300d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(inputs=None, n_filters=None, dropout_prob=0, max_pooling=True):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    Arguments:\n",
    "        inputs -- Input tensor\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        dropout_prob -- Dropout probability\n",
    "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
    "    Returns: \n",
    "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
    "    \"\"\"\n",
    "    conv = Conv2D(n_filters, 3, activation='relu', padding='same',\n",
    "                  kernel_initializer='he_normal')(inputs)\n",
    "    conv = Conv2D(n_filters, 3, activation='relu', padding='same',\n",
    "                  kernel_initializer='he_normal')(conv)\n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(2,strides=2)(conv)\n",
    "    else:\n",
    "        next_layer = conv\n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection\n",
    "\n",
    "def upsampling_block(expansive_input, contractive_input, n_filters=None):\n",
    "    \"\"\"\n",
    "    Convolutional upsampling block\n",
    "    Returns: \n",
    "        conv -- Tensor output\n",
    "    \"\"\"\n",
    "    up = Conv2DTranspose(n_filters,3,strides=2,padding='same')(expansive_input)\n",
    "    merge = concatenate([up, contractive_input], axis=3)\n",
    "    conv = Conv2D(n_filters, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge)\n",
    "    conv = Conv2D(n_filters, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def unet_model7(input_size=(1024, 1024, 1), n_filters=4, n_classes=7):\n",
    "    \"\"\"\n",
    "    Function name changed to unet_model7\n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    inputs = Input(input_size)\n",
    "    # Contracting Path (encoding)\n",
    "    cblock0 = conv_block(inputs, 8)\n",
    "    cblock1 = conv_block(cblock0[0], 8)\n",
    "    cblock2 = conv_block(cblock1[0], 16)\n",
    "    cblock3 = conv_block(cblock2[0], 32)\n",
    "    cblock4 = conv_block(cblock3[0], 64)\n",
    "    cblock5 = conv_block(cblock4[0], 128)\n",
    "    cblock6 = conv_block(cblock5[0], 256, 0.3) # Include a dropout_prob of 0.3 for this layer\n",
    "    cblock7 = conv_block(cblock6[0], 512, 0.3, max_pooling=False) \n",
    "    # Expanding Path (decoding)\n",
    "    ublock8 = upsampling_block(cblock7[0], cblock6[1], n_filters * 64)\n",
    "    ublock9 = upsampling_block(ublock8, cblock5[1],  128)\n",
    "    ublock10 = upsampling_block(ublock9, cblock4[1],  64)\n",
    "    ublock11 = upsampling_block(ublock10, cblock3[1],  32)\n",
    "    ublock12 = upsampling_block(ublock11, cblock2[1],  16)\n",
    "    ublock13 = upsampling_block(ublock12, cblock1[1],  8)\n",
    "    ublock14 = upsampling_block(ublock13, cblock0[1],  8)\n",
    "    conv9 = Conv2D(n_filters, 3, activation='relu', padding='same', kernel_initializer='he_normal')(ublock14)\n",
    "    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77aa083-8891-41d5-a511-fa6d07202b1b",
   "metadata": {},
   "source": [
    "## Model definition, compilation and loading of trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4441212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1024, 1024, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 1024, 1024, 8)        80        ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 1024, 1024, 8)        584       ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 512, 512, 8)          0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 512, 512, 8)          584       ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 512, 512, 8)          584       ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 256, 256, 8)          0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 256, 256, 16)         1168      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 256, 256, 16)         2320      ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 128, 128, 16)         0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 128, 128, 32)         4640      ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 64, 64, 32)           0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 64)           18496     ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 32, 32, 64)           0         ['conv2d_9[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 128)          73856     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 128)          147584    ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_11[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 16, 16, 256)          295168    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 256)          590080    ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 16, 16, 256)          0         ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 8, 8, 256)            0         ['dropout[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 8, 8, 512)            1180160   ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 8, 8, 512)            2359808   ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 8, 8, 512)            0         ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 16, 16, 256)          1179904   ['dropout_1[0][0]']           \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 16, 16, 512)          0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 16, 16, 256)          1179904   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 256)          590080    ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 32, 32, 128)          295040    ['conv2d_17[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 32, 32, 256)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 32, 32, 128)          295040    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 32, 32, 128)          147584    ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 64, 64, 64)           73792     ['conv2d_19[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 64)           36928     ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 128, 128, 32)         18464     ['conv2d_21[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 128, 128, 32)         18464     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 128, 128, 32)         9248      ['conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 256, 256, 16)         4624      ['conv2d_23[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_4[0][0]',  \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 256, 256, 16)         4624      ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 256, 256, 16)         2320      ['conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2D  (None, 512, 512, 8)          1160      ['conv2d_25[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 512, 512, 16)         0         ['conv2d_transpose_5[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 512, 512, 8)          1160      ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 512, 512, 8)          584       ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 1024, 1024, 8)        584       ['conv2d_27[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 1024, 1024, 16)       0         ['conv2d_transpose_6[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 1024, 1024, 8)        1160      ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 1024, 1024, 8)        584       ['conv2d_28[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 1024, 1024, 4)        292       ['conv2d_29[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 1024, 1024, 7)        35        ['conv2d_30[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8656655 (33.02 MB)\n",
      "Trainable params: 8656655 (33.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# segmenter location's model is unet_loc\n",
    "img_height = 1024\n",
    "img_width = 1024\n",
    "num_channels = 1\n",
    " \n",
    "unet_loc = unet_model7((img_height, img_width, num_channels))\n",
    "unet_loc.summary()     # generates summary listed below this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4df734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses Nadam optimizer.  When starting with highly trained weights, use next cell (Adam)\n",
    "unet_loc.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=2e-3),    # ATTENTION NAdam\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              # metrics=['accuracy'])\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name= \"Sparse Categorical Accuracy\")])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c644c900-0f34-4e18-9c64-d839eb178784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses Adam optimizer.\n",
    "unet_loc.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),   # final stages at 8e-5\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              # metrics=['accuracy'])\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name= \"Sparse Categorical Accuracy\")])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca2a5f-9f65-4202-8906-1c547394b3cb",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "022d2fe7-3d03-4796-8ae2-729e8f310c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_tuning_counter = 0\n",
    "acc = [0.]  \n",
    "loss = [0.]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57930e7b-6f81-4080-8f74-b7535c8d6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training\n",
    "checkpoint_filepath = 'C:/Users/erios/checkpoints/checkpoint_unet_loc_paul2b'  #2b is for use with 6 labels\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,  save_weights_only=True, monitor=\"Sparse Categorical Accuracy\",\n",
    "    mode='max', save_best_only=True)\n",
    "image_ds = dataset.map(process_path)                       \n",
    "processed_image_ds = image_ds.map(preprocess)              \n",
    "#BUFFER_SIZE = 147\n",
    "#BATCH_SIZE = 9\n",
    "BUFFER_SIZE = 17\n",
    "BATCH_SIZE = 3\n",
    "train_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "if coarse_tuning_counter == 0:\n",
    "    initial_epochs = 4         # use in general 5\n",
    "    total_epochs = initial_epochs\n",
    "    history = unet_loc.fit(train_dataset, epochs=initial_epochs)\n",
    "else:\n",
    "    more_epochs = 20\n",
    "    total_epochs =  total_epochs + more_epochs\n",
    "    history = unet_loc.fit(train_dataset, epochs=total_epochs, \n",
    "                           initial_epoch=history.epoch[-1], callbacks=[model_checkpoint_callback])\n",
    "coarse_tuning_counter += 1    \n",
    "# update history\n",
    "acc += history.history['Sparse Categorical Accuracy']\n",
    "loss += history.history['loss']# plot evolution of accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad120816-1383-435c-a7e8-b0a6d02d3733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# update history\n",
    "#acc += history.history['Sparse Categorical Accuracy']\n",
    "#loss += history.history['loss']# plot evolution of accuracy and loss\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Sparse Categorical Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Sparse Categorical Cross Entropy')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f466603-c1a2-448c-b56d-8a1696f8c1fd",
   "metadata": {},
   "source": [
    "## Prediction on a \"validation\" or \"test\" set. Assumes a ...val_labels folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e48b5a-a24d-4fd0-8a16-c496879f4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a \"test\" dataset --will not be used in training--  \n",
    "path= ''\n",
    "# image_path_val = os.path.join(path, 'C:/Users/erios/EM_Images/split_random_granules_val/')\n",
    "# mask_path_val = os.path.join(path, 'C:/Users/erios/EM_Images/split_random_granules_val_labels/')\n",
    "image_path_val = os.path.join(path, 'C:/Users/erios/EM_Images/split_randomized_renamed_ping_val/')\n",
    "mask_path_val = os.path.join(path, 'C:/Users/erios/EM_Images/split_r_labels_6_val/')\n",
    "image_list_orig_val = os.listdir(image_path_val)   # a list of image file names\n",
    "mask_list_orig_val = os.listdir(mask_path_val)\n",
    "image_list_val = [image_path_val+i for i in image_list_orig_val]   # a list of image file names that includes the ful path\n",
    "mask_list_val = [mask_path_val+i for i in mask_list_orig_val]   # print(image_list_val[0:1])\n",
    "image_filenames_val = tf.constant(image_list_val)   #tensor, dtype = string\n",
    "mask_filenames_val = tf.constant(mask_list_val)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((image_filenames_val, mask_filenames_val))   #a dataset of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef5f4372-efa8-4441-8f16-e716bc6d4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation .  Preprocess does not include data augmentation \n",
    "def process_path(image_path, mask_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=0, dtype=tf.dtypes.uint16)\n",
    "    return img, mask\n",
    "\n",
    "def preprocess_val(image, mask):\n",
    "    input_image = tf.image.resize(image, (1024,1024), method='nearest')\n",
    "    input_mask = tf.image.resize(mask, (1024,1024), method='nearest')\n",
    "    return input_image, input_mask\n",
    "\n",
    "image_ds_val = dataset_val.map(process_path)\n",
    "processed_image_ds_val = image_ds_val.map(preprocess_val)\n",
    "val_dataset = processed_image_ds_val.cache().batch(1)    #either way of batching works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf6a2f-502d-4174-a6e4-1639f525277a",
   "metadata": {},
   "source": [
    "## Prediction and output of images as png files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed0444-4246-4955-af8d-8f7d7d4c33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_val = unet_loc.predict(val_dataset)   #makes an np probability array  rank 4\n",
    "n = probs_val.shape[0]                  # the number of images in the val dataset\n",
    "probs1_val =  np.vsplit(probs_val, n)  #makes a list of n probability arrays (1024, 1024, 2)\n",
    "pred_m_l_val= [np.zeros((1024,1024,2),dtype=float) for i in range(n)]   #initialization of a list of np.arrays\n",
    "pred_val_acc_list= [0.0 for i in range(n)]\n",
    "for i in range (n):\n",
    "    pred_m_l_val[i] = create_mask((probs1_val[i]))      #list gets populated by prediction masks\n",
    "# now will write prediction masks to ping files, with same names as original image files in val folder\n",
    "DIR = \"C:/Users/erios/EM_Images/split_r_labels_6_val_preds/\"\n",
    "for i in range(n):\n",
    "    name=DIR + str(image_list_orig_val[i])            # list of original image file names\n",
    "    mask = tf.cast(pred_m_l_val[i],tf.uint16)         #  had to recast numpy prediction masks as uint16 (from int32)\n",
    "    pred_png = tf.image.encode_png(mask)              #  otherwise, the encoder would not work\n",
    "    with open(name, 'wb') as f:\n",
    "        f.write(pred_png.numpy())                     #  works well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926f212-ba32-4946-830b-6b5694f20158",
   "metadata": {},
   "source": [
    "## Calculates accuracies for the entire val set and outputs them in a text file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf3be0b-b859-4dc7-9b3a-6de9ff474f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.Accuracy()\n",
    "true_m_l_val= [np.zeros((1024,1024,2),dtype=float) for i in range(n)]   #initialization of a list of np.arrays true masks\n",
    "count = 0\n",
    "for image, mask in val_dataset:\n",
    "        true_m_l_val[count] = mask[0]                                   # squeezes the first dimension; needed for accuracy calculation\n",
    "        count=count+1\n",
    "for i in range(n):\n",
    "    m.update_state([pred_m_l_val[i]],[ true_m_l_val[i]])\n",
    "    pred_val_acc_list[i] = m.result().numpy()                           # the accuracy function works in roundabout way\n",
    "accuracy_out = DIR+\"accuracies.txt\"\n",
    "f = open(accuracy_out, \"w\")\n",
    "for i in range(n):\n",
    "    f.write(\"\\n\"+str(i)+\"    \"+str(pred_val_acc_list[i]) )               # a two-column text output\n",
    "f.close()\n",
    "#from statistics import mean\n",
    "print(pred_val_acc_list,sum(pred_val_acc_list)/14.)\n",
    "print(statistics.mean(pred_val_acc_list[0:7]), statistics.stdev(pred_val_acc_list[0:7]))\n",
    "# Outputs loss and accuracy lists to text files in DIR.  Could change DIR\n",
    "loss_out = DIR+\"loss_vs_epoch.txt\"                      # defines output file name\n",
    "f = open(loss_out, \"w\")                                 # logical name of output file\n",
    "for i in range(25):\n",
    "    f.write(\"\\n\"+str(i)+\"    \"+str(loss[i]) )               # a two-column text output\n",
    "f.close()\n",
    "#probs = unet.predict(train_dataset)   #makes an np array (n_elements in train_dataset, 1024, 1024, 2)\n",
    "probs1 =  np.vsplit(probs, 64)  #makes a list of arrays (1024, 1024, 2)\n",
    "pred_m_l= [np.zeros((1024,1024,2),dtype=float) for i in range(64)]   #initialization of a list of np.arrays\n",
    "for i in range (64):\n",
    "    pred_m_l[i] = create_mask((probs1[i]))      #list gets populated\n",
    "# The above list can be written to files as with the val set or used for calculation of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8c914-81a2-467c-9f71-13ef688b98ba",
   "metadata": {},
   "source": [
    "# PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d004c-978a-4788-81d7-0300f9787a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"a production run requires loading libraries, defining the input dataset, assembling and compiling the model, defining utilities \n",
    "(display_prod, create_mask, process_path, preprocess_prod, show_predictions_prod, and probs_prod, which performs the prediction and outputs the ping predi\n",
    "predicted masks.  # preparing a production dataset.  No masks. \"\"\"\n",
    "path= ''\n",
    "image_path_prod = os.path.join(path, 'C:/Users/erios/EM_Images/037_split_for_segmentation/')\n",
    "image_list_orig_prod = os.listdir(image_path_prod)   # a list of image file names\n",
    "image_list_prod = [image_path_prod+i for i in image_list_orig_prod]   # a list of image file names that includes the full path\n",
    "image_filenames_prod = tf.constant(image_list_prod)   #tensor, dtype = string\n",
    "\n",
    "dataset_prod = tf.data.Dataset.from_tensor_slices((image_filenames_prod))   #a dataset of filenames\n",
    "print(len(image_list_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50a2920-33f0-4ccb-9ff8-30d5f402ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction from model outputs\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "    # Production .  Preprocess does not include data augmentation \n",
    "def process_path(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    return img\n",
    "\n",
    "def preprocess_prod(image):\n",
    "    input_image = tf.image.resize(image, (1024,1024), method='nearest')\n",
    "    return input_image\n",
    "\n",
    "image_ds_prod = dataset_prod.map(process_path)\n",
    "processed_image_ds_prod = image_ds_prod.map(preprocess_prod)\n",
    "#prod_dataset is the production dataset, batched and cached for application of prediction. Not to be confused with dataset_prod\n",
    "prod_dataset = processed_image_ds_prod.cache().batch(20)    #either way of batching works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500eb52-4336-4336-83d1-6237ea2b5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production\n",
    "probs_prod = unet_loc.predict(prod_dataset)   #  PREDICTS! makes an np probability array  rank 4\n",
    "n = probs_prod.shape[0]                  # the number of images in the prod dataset\n",
    "probs1_prod =  np.vsplit(probs_prod, n)  #makes a list of n probability arrays (1024, 1024, 2)\n",
    "pred_m_l_prod= [np.zeros((1024,1024,2),dtype=float) for i in range(n)]   #initialization of a list of np.arrays\n",
    "pred_prod_acc_list= [0.0 for i in range(n)]\n",
    "for i in range (n):\n",
    "    pred_m_l_prod[i] = create_mask((probs1_prod[i]))      #list gets populated by prediction masks\n",
    "#display([pred_m_l_prod[4]])   #nice check\n",
    "# now will write prediction masks to ping files, with same names as original image files in val folder\n",
    "DIR = \"C:/Users/erios/EM_Images/037_split_for_segmentation_loc_preds/\"  # make sure folder is present\n",
    "for i in range(n):\n",
    "    name=DIR + str(image_list_orig_prod[i])            # list of original image file names\n",
    "    mask = tf.cast(pred_m_l_prod[i],tf.uint16)         #  had to recast numpy prediction masks as uint16 (from int32)\n",
    "    pred_png = tf.image.encode_png(mask)              #  otherwise, the encoder would not work\n",
    "    with open(name, 'wb') as f:\n",
    "        f.write(pred_png.numpy())                     #  works well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9242fb0-9298-4bec-ae2b-2b8668b677e7",
   "metadata": {},
   "source": [
    "## Studying Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ffabfb-4c1f-4665-881c-b8bcdb03ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.Accuracy()\n",
    "m.update_state([sample_mask],[ predicted_mask])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ea4f5-f583-4fe1-a146-6db4a7c2754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])  IoU depends on the target class\n",
    "mi.update_state([sample_mask],[ predicted_mask])\n",
    "mi.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506596c-1b2c-40f2-881a-c15d9df0bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0])\n",
    "mi.update_state([sample_mask],[ predicted_mask])\n",
    "mi.result().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
